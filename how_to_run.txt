Steps to run this project:

1. Follow the torch-ngp (https://github.com/ashawkey/torch-ngp) directions on setting up a conda environment.
The provided environment.yml is the same as in torch-ngp. There may be additional libraries that you have to 
conda-install. 

2. Then, run NeRF training. Make sure your training data (from Blender) is located in data/nerf_synthetic/model_name. This 
format should be identical to most NeRF repositories. The command to train on Blender scenes is: 

python main_nerf.py data/nerf_synthetic/model_name --workspace model_name_nerf -O --bound x.x --scale 1.0 --dt_gamma 0

It is imperative you set scale to 1.0, so that ngp does not resize the scene dimensions and cause a mismatch between the 
scale of the model dynamics and that of the NeRF. Set bound to be the bounding box of your Blender mesh. For example, for 
the Stonehenge scene, we used --bound 2.0

3. Once training has finished or you've achieved satisfactory results, the checkpoint will be in the model_name_nerf folder. 

4. Make sure to download the latest version of Blender. Provided in the Google drive is the Stonehenge scene used to gather
training images located in data/nerf_synthetic/model_name. This time, we will use Blender as our simulation environment. 
First, open a new terminal in the folder where Blender is located and open blender (i.e. ./blender in the terminal). This 
allows the user to break out of hanging scripts through the terminal. Once Blender is open, navigate to the Scripting tab, 
and open visualize.py if it is not already in the tab.

5. Create a sim_img_cache folder if it is not already there. This is where visualize.py will read in poses of the robot 
and return an observation image. 

6. Run visualize.py in Blender by pressing the run button.

7. Run the planning/estimation loop (in a terminal different than the one visualize.py is on) using the command:

python simulate.py data/nerf_synthetic/model_name --workspace model_name_nerf -O --bound x.x --scale 1.0 --dt_gamma 0

It is imperative that the parameters you pass in are the same as those used to train the NeRF (i.e. --bound, --scale, --dt_gamma).
All tunable configs are in simulate.py. 
